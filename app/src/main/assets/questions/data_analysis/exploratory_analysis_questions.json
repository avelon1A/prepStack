{
  "topicId": "exploratory_analysis",
  "questions": [
    {"id": "eda_theory_1", "questionText": "What is Exploratory Data Analysis (EDA) and what are its main objectives?", "type": "THEORY", "correctAnswer": "Exploratory Data Analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often using visual methods. The main objectives include: 1) Understanding the data structure and variables, 2) Detecting patterns and relationships, 3) Identifying outliers and anomalies, 4) Testing assumptions for modeling, and 5) Generating hypotheses for further investigation.", "explanation": "EDA is typically the first step in data analysis, performed before formal modeling or hypothesis testing. It helps analysts get a 'feel' for the data and guides subsequent analytical decisions.", "difficulty": "EASY"},
    
    {"id": "eda_theory_2", "questionText": "What are the key descriptive statistics used in EDA and what do they tell us?", "type": "THEORY", "correctAnswer": "Key descriptive statistics include: 1) Measures of central tendency (mean, median, mode) to identify typical values, 2) Measures of spread (range, variance, standard deviation, IQR) to understand variability, 3) Measures of shape (skewness, kurtosis) to characterize the distribution, and 4) Measures of position (percentiles, quartiles) to understand where values fall within the distribution.", "explanation": "These statistics provide a numerical summary of different aspects of the data, helping analysts identify patterns and characteristics that might not be immediately visible in the raw data.", "difficulty": "MEDIUM"},
    
    {"id": "eda_theory_3", "questionText": "What is the role of data visualization in EDA and what are some commonly used visualization techniques?", "type": "THEORY", "correctAnswer": "Visualization in EDA helps identify patterns, trends, relationships, and anomalies that might not be apparent in numerical summaries. Common visualization techniques include: 1) Histograms and density plots for distributions, 2) Box plots for summary statistics and outliers, 3) Scatter plots for relationships between variables, 4) Heatmaps for correlation matrices, 5) Pair plots for multiple variable interactions, and 6) Time series plots for temporal patterns.", "explanation": "The human visual system is highly adept at recognizing patterns, making visualization an indispensable tool in EDA. Different visualization types serve different analytical purposes.", "codeExample": "# Python examples of common EDA visualizations\n\n# Histogram\nimport matplotlib.pyplot as plt\nplt.hist(df['column'], bins=30)\nplt.title('Distribution of Values')\nplt.show()\n\n# Box plot\nimport seaborn as sns\nsns.boxplot(x='category', y='value', data=df)\nplt.title('Values by Category')\nplt.show()\n\n# Correlation heatmap\ncorr_matrix = df.corr()\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.show()", "difficulty": "MEDIUM"},
    
    {"id": "eda_theory_4", "questionText": "What is the difference between univariate, bivariate, and multivariate analysis in EDA?", "type": "THEORY", "correctAnswer": "Univariate analysis examines one variable at a time, focusing on its distribution, central tendency, and spread. Bivariate analysis explores the relationship between two variables, looking for correlations and patterns. Multivariate analysis investigates relationships between three or more variables simultaneously, often using dimensionality reduction techniques or multivariate visualizations.", "explanation": "Each type provides different insights: univariate for understanding individual variables, bivariate for exploring relationships, and multivariate for investigating complex interactions that may not be visible in simpler analyses.", "difficulty": "EASY"},
    
    {"id": "eda_theory_5", "questionText": "How can you detect and assess multicollinearity during EDA?", "type": "THEORY", "correctAnswer": "Multicollinearity (high correlation between predictor variables) can be detected through: 1) Correlation matrices and heatmaps to identify high pairwise correlations, 2) Variance Inflation Factor (VIF) to quantify the degree of multicollinearity, 3) Eigenvalues of the correlation matrix, and 4) Condition numbers to assess the overall multicollinearity in the dataset.", "explanation": "Multicollinearity can cause instability in model coefficients and reduce predictive power. Detecting it during EDA helps inform feature selection, engineering, or regularization techniques in subsequent modeling.", "codeExample": "# Python example for detecting multicollinearity\n\n# Correlation matrix\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\ncorr_matrix = df[['var1', 'var2', 'var3']].corr()\nsns.heatmap(corr_matrix, annot=True)\n\n# Variance Inflation Factor (VIF)\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\ndef calculate_vif(df, features):\n    vif_data = pd.DataFrame()\n    vif_data[\"Variable\"] = features\n    vif_data[\"VIF\"] = [variance_inflation_factor(\n        df[features].values, i) for i in range(len(features))]\n    return vif_data", "difficulty": "HARD"}
  ]
}